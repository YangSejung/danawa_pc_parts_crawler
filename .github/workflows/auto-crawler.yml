name: Daily Crawler Update

on:
  workflow_dispatch:
  #schedule:
    #- cron: '0 0 * * *'  # 매일 자정 UTC (= 한국 9AM)
    #- cron: '/10 * * * *'  # 매일 자정 UTC (= 한국 9AM)

jobs:
  update-data:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Ensure driver/ folder exists
      run: mkdir -p driver

    - name: Install dependencies
      run: python -m pip install --upgrade pip

    - name: Install ChromeDriver matching system Chrome
      run: |
        FULL_VER=$(google-chrome --version | grep -oP '\d+\.\d+\.\d+')
        echo "Detected Chrome version: $FULL_VER"
        
        # 메이저 버전(첫 번째 숫자)만 남김
        MAJOR_VER=${FULL_VER%%.*}
        echo "Using major version: $MAJOR_VER"
        
        # 해당 메이저 버전에 맞는 ChromeDriver 버전 조회
        DRIVER_VERSION=$(curl -s "https://chromedriver.storage.googleapis.com/${FULL_VER}")
        echo "Matching ChromeDriver version: $DRIVER_VERSION"
        
        # Download and unzip
        wget -N "https://chromedriver.storage.googleapis.com/${DRIVER_VERSION}/chromedriver_linux64.zip"
        unzip -q chromedriver_linux64.zip -d driver/
        chmod +x chromedriver

    - name: Run Crawler
      run: |
        python crawlers/parts_info_crawler.py

    - name: Push
      uses: stefanzweifel/git-auto-commit-action@v5
      with:
        commit_message: "Bot - Auto Crawl | $(date -d '+9 hour' +'%Y-%m-%d %H:%M:%S')"
        file_pattern: