name: Daily Crawler Update

on:
  workflow_dispatch:
  #schedule:
    #- cron: '0 0 * * *'  # 매일 자정 UTC (= 한국 9AM)
    #- cron: '/10 * * * *'  # 매일 자정 UTC (= 한국 9AM)

jobs:
  update-data:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Ensure driver/ folder exists
      run: mkdir -p driver

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Install ChromeDriver matching system Chrome
      run: |
        FULL_VER=$(google-chrome --version | grep -oP '\d+\.\d+\.\d+')
        echo "Detected Chrome version: $FULL_VER"
        
        # Download and unzip
        wget https://storage.googleapis.com/chrome-for-testing-public/${FULL_VER}/linux64/chromedriver-linux64.zip
        unzip -q chromedriver-linux64.zip -d driver/

    - name: Run Crawler
      run: |
        python crawlers/parts_info_crawler.py

    - name: Push
      uses: stefanzweifel/git-auto-commit-action@v5
      with:
        commit_message: "Bot - Auto Crawl | $(date -d '+9 hour' +'%Y-%m-%d %H:%M:%S')"
        file_pattern: