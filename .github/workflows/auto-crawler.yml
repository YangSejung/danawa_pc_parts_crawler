name: Daily Crawler Update

on:
  workflow_dispatch:
  #schedule:
    #- cron: '0 0 * * *'  # 매일 자정 UTC (= 한국 9AM)
    #- cron: '/10 * * * *'  # 매일 자정 UTC (= 한국 9AM)

jobs:
  update-data:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
      with:
        persist-credentials: true

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Install ChromeDriver matching system Chrome
      run: |
        mkdir -p driver
        
        FULL_VER=$(google-chrome --version | grep -oP '\d+\.\d+\.\d+\.\d+')
        echo "Detected Chrome version: $FULL_VER"
      
        # Download and unzip
        wget https://storage.googleapis.com/chrome-for-testing-public/${FULL_VER}/linux64/chromedriver-linux64.zip
        unzip -q -j -o chromedriver-linux64.zip -d driver/ 
        rm chromedriver-linux64.zip

    - name: Run Crawler
      run: |
        python crawlers/parts_info_crawler.py

    - name: Push
      uses: stefanzweifel/git-auto-commit-action@v5
      with:
        commit_message: "Bot - Auto Crawl | $(date -d '+9 hour' +'%Y-%m-%d %H:%M:%S')"
        file_pattern: "data/raw/**"
      env:
        github_token: ${{ secrets.GITHUB_TOKEN }}